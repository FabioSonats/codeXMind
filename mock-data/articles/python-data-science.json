{
    "id": "11",
    "title": "Python para Data Science: Pandas e NumPy",
    "slug": "python-data-science",
    "excerpt": "Aprenda a usar Pandas e NumPy para análise de dados e ciência de dados com Python",
    "content": "# Python para Data Science: Pandas e NumPy\n\nPython é uma das linguagens mais populares para Data Science. Vamos explorar as principais bibliotecas: Pandas e NumPy.\n\n## NumPy - Arrays Multidimensionais\n\n```python\nimport numpy as np\n\n# Criando arrays\narr1 = np.array([1, 2, 3, 4, 5])\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\narr3 = np.zeros((3, 4))  # Array de zeros\narr4 = np.ones((2, 3))   # Array de uns\narr5 = np.random.random((2, 3))  # Array aleatório\n\nprint(f\"Array 1D: {arr1}\")\nprint(f\"Array 2D: {arr2}\")\nprint(f\"Shape: {arr2.shape}\")\nprint(f\"Dtype: {arr2.dtype}\")\n\n# Operações matemáticas\narr_a = np.array([1, 2, 3, 4])\narr_b = np.array([5, 6, 7, 8])\n\nprint(f\"Soma: {arr_a + arr_b}\")\nprint(f\"Multiplicação: {arr_a * arr_b}\")\nprint(f\"Média: {np.mean(arr_a)}\")\nprint(f\"Desvio padrão: {np.std(arr_a)}\")\n\n# Indexação e slicing\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(f\"Primeira linha: {arr[0]}\")\nprint(f\"Primeira coluna: {arr[:, 0]}\")\nprint(f\"Subarray: {arr[1:3, 1:3]}\")\n\n# Reshape\narr_flat = np.array([1, 2, 3, 4, 5, 6])\narr_reshaped = arr_flat.reshape(2, 3)\nprint(f\"Reshaped: {arr_reshaped}\")\n```\n\n## Pandas - Manipulação de Dados\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Criando DataFrames\n# A partir de dicionário\ndata = {\n    'Nome': ['João', 'Maria', 'Pedro', 'Ana'],\n    'Idade': [25, 30, 35, 28],\n    'Salário': [5000, 6000, 7000, 5500],\n    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Salvador']\n}\n\ndf = pd.DataFrame(data)\nprint(df)\nprint(f\"\\nInfo do DataFrame:\")\nprint(df.info())\nprint(f\"\\nEstatísticas descritivas:\")\nprint(df.describe())\n\n# A partir de CSV\n# df = pd.read_csv('dados.csv')\n\n# A partir de Excel\n# df = pd.read_excel('dados.xlsx')\n\n# Visualizando dados\nprint(f\"\\nPrimeiras 3 linhas:\")\nprint(df.head(3))\n\nprint(f\"\\nÚltimas 2 linhas:\")\nprint(df.tail(2))\n\nprint(f\"\\nAmostra aleatória:\")\nprint(df.sample(2))\n```\n\n## Seleção e Filtragem\n\n```python\n# Seleção de colunas\nprint(f\"Apenas nome e idade:\")\nprint(df[['Nome', 'Idade']])\n\n# Seleção de linhas\nprint(f\"\\nPrimeiras 2 linhas:\")\nprint(df.iloc[0:2])\n\nprint(f\"\\nLinhas com índice específico:\")\nprint(df.loc[0:2])\n\n# Filtragem\nprint(f\"\\nPessoas com mais de 30 anos:\")\nprint(df[df['Idade'] > 30])\n\nprint(f\"\\nPessoas de São Paulo:\")\nprint(df[df['Cidade'] == 'São Paulo'])\n\n# Filtros múltiplos\nprint(f\"\\nPessoas com mais de 25 anos E salário maior que 5000:\")\nprint(df[(df['Idade'] > 25) & (df['Salário'] > 5000)])\n\n# Filtros com isin\nprint(f\"\\nPessoas de São Paulo ou Rio de Janeiro:\")\nprint(df[df['Cidade'].isin(['São Paulo', 'Rio de Janeiro'])])\n```\n\n## Operações com Dados\n\n```python\n# Adicionando colunas\ndf['Salário_Anual'] = df['Salário'] * 12\ndf['Faixa_Etaria'] = df['Idade'].apply(lambda x: 'Jovem' if x < 30 else 'Adulto')\n\nprint(f\"DataFrame com novas colunas:\")\nprint(df)\n\n# Agrupamento\ngrupo_cidade = df.groupby('Cidade')\nprint(f\"\\nMédia de salário por cidade:\")\nprint(grupo_cidade['Salário'].mean())\n\nprint(f\"\\nContagem por cidade:\")\nprint(grupo_cidade.size())\n\n# Agregações múltiplas\nagregacoes = df.groupby('Cidade').agg({\n    'Salário': ['mean', 'min', 'max'],\n    'Idade': 'mean'\n})\nprint(f\"\\nAgregações por cidade:\")\nprint(agregacoes)\n\n# Ordenação\nprint(f\"\\nOrdenado por salário (decrescente):\")\nprint(df.sort_values('Salário', ascending=False))\n\n# Valores únicos\nprint(f\"\\nCidades únicas:\")\nprint(df['Cidade'].unique())\n\nprint(f\"\\nContagem de valores:\")\nprint(df['Cidade'].value_counts())\n```\n\n## Limpeza de Dados\n\n```python\n# Criando DataFrame com dados \"sujos\"\ndata_suja = {\n    'Nome': ['João', 'Maria', None, 'Ana', ''],\n    'Idade': [25, 30, 35, None, 28],\n    'Salário': [5000, 6000, 7000, 5500, -1000],\n    'Email': ['joao@email.com', 'maria@email.com', 'pedro@email.com', 'ana@email.com', 'invalido']\n}\n\ndf_sujo = pd.DataFrame(data_suja)\nprint(f\"DataFrame com dados sujos:\")\nprint(df_sujo)\n\n# Verificando valores nulos\nprint(f\"\\nValores nulos:\")\nprint(df_sujo.isnull().sum())\n\n# Removendo linhas com valores nulos\ndf_limpo = df_sujo.dropna()\nprint(f\"\\nApós remover nulos:\")\nprint(df_limpo)\n\n# Preenchendo valores nulos\ndf_preenchido = df_sujo.fillna({\n    'Nome': 'Desconhecido',\n    'Idade': df_sujo['Idade'].mean()\n})\nprint(f\"\\nApós preencher nulos:\")\nprint(df_preenchido)\n\n# Removendo duplicatas\ndf_duplicado = pd.concat([df, df.iloc[0:2]])  # Duplicando primeiras 2 linhas\nprint(f\"\\nDataFrame com duplicatas:\")\nprint(df_duplicado)\n\ndf_sem_duplicatas = df_duplicado.drop_duplicates()\nprint(f\"\\nApós remover duplicatas:\")\nprint(df_sem_duplicatas)\n\n# Tratando outliers (salários negativos)\nprint(f\"\\nRemovendo salários negativos:\")\ndf_sem_outliers = df_sujo[df_sujo['Salário'] > 0]\nprint(df_sem_outliers)\n```\n\n## Análise Estatística\n\n```python\n# Estatísticas descritivas\nprint(f\"Estatísticas descritivas:\")\nprint(df.describe())\n\n# Correlação\nprint(f\"\\nMatriz de correlação:\")\nprint(df[['Idade', 'Salário', 'Salário_Anual']].corr())\n\n# Distribuição\nprint(f\"\\nDistribuição de idades:\")\nprint(df['Idade'].value_counts().sort_index())\n\n# Percentis\nprint(f\"\\nPercentis do salário:\")\nprint(df['Salário'].quantile([0.25, 0.5, 0.75, 0.9, 0.95]))\n\n# Análise por grupos\nprint(f\"\\nAnálise por faixa etária:\")\nanalise_grupos = df.groupby('Faixa_Etaria').agg({\n    'Salário': ['count', 'mean', 'std'],\n    'Idade': ['min', 'max']\n})\nprint(analise_grupos)\n```\n\n## Visualização com Matplotlib\n\n```python\nimport matplotlib.pyplot as plt\n\n# Configurando o estilo\nplt.style.use('seaborn-v0_8')\n\n# Gráfico de barras\nplt.figure(figsize=(10, 6))\nplt.subplot(2, 2, 1)\ndf['Cidade'].value_counts().plot(kind='bar')\nplt.title('Distribuição por Cidade')\nplt.xticks(rotation=45)\n\n# Histograma\nplt.subplot(2, 2, 2)\nplt.hist(df['Salário'], bins=10, alpha=0.7, color='skyblue')\nplt.title('Distribuição de Salários')\nplt.xlabel('Salário')\nplt.ylabel('Frequência')\n\n# Scatter plot\nplt.subplot(2, 2, 3)\nplt.scatter(df['Idade'], df['Salário'], alpha=0.7)\nplt.title('Idade vs Salário')\nplt.xlabel('Idade')\nplt.ylabel('Salário')\n\n# Box plot\nplt.subplot(2, 2, 4)\ndf.boxplot(column='Salário', by='Faixa_Etaria')\nplt.title('Salário por Faixa Etária')\nplt.suptitle('')  # Remove título automático\n\nplt.tight_layout()\nplt.show()\n```\n\n## Trabalhando com Datas\n\n```python\n# Criando DataFrame com datas\ndata_vendas = {\n    'Data': pd.date_range('2025-01-01', periods=30, freq='D'),\n    'Vendas': np.random.randint(1000, 5000, 30),\n    'Produto': np.random.choice(['A', 'B', 'C'], 30)\n}\n\ndf_vendas = pd.DataFrame(data_vendas)\nprint(f\"DataFrame de vendas:\")\nprint(df_vendas.head())\n\n# Operações com datas\ndf_vendas['Ano'] = df_vendas['Data'].dt.year\ndf_vendas['Mês'] = df_vendas['Data'].dt.month\ndf_vendas['Dia_Semana'] = df_vendas['Data'].dt.day_name()\n\nprint(f\"\\nCom colunas de data:\")\nprint(df_vendas.head())\n\n# Agrupamento por período\nvendas_por_mes = df_vendas.groupby('Mês')['Vendas'].sum()\nprint(f\"\\nVendas por mês:\")\nprint(vendas_por_mes)\n\n# Filtro por período\nvendas_janeiro = df_vendas[df_vendas['Data'].dt.month == 1]\nprint(f\"\\nVendas de janeiro:\")\nprint(vendas_janeiro)\n```\n\n## Exportando Dados\n\n```python\n# Exportando para CSV\ndf.to_csv('dados_limpos.csv', index=False)\n\n# Exportando para Excel\ndf.to_excel('dados_limpos.xlsx', index=False, sheet_name='Funcionarios')\n\n# Exportando para JSON\ndf.to_json('dados_limpos.json', orient='records')\n\n# Exportando para HTML\ndf.to_html('dados_limpos.html')\n\nprint(\"Dados exportados com sucesso!\")\n```\n\n## Conclusão\n\nPandas e NumPy são ferramentas essenciais para Data Science em Python:\n\n**NumPy:**\n- Arrays multidimensionais eficientes\n- Operações matemáticas vetorizadas\n- Base para outras bibliotecas\n\n**Pandas:**\n- Manipulação de dados estruturados\n- Limpeza e transformação de dados\n- Análise estatística\n- Integração com outras ferramentas\n\n**Próximos passos:**\n- Matplotlib/Seaborn para visualização\n- Scikit-learn para machine learning\n- Jupyter Notebooks para análise interativa\n- SQLAlchemy para integração com bancos de dados\n\nEssas bibliotecas formam a base sólida para qualquer projeto de Data Science!",
    "author": {
        "id": "1",
        "name": "Fábio Ferreira",
        "avatar": "/avatars/fabio.jpg",
        "bio": "Desenvolvedor Full-Stack e criador de conteúdo técnico",
        "social": {
            "github": "https://github.com/FabioSonats",
            "linkedin": "https://www.linkedin.com/in/ferreira-f%C3%A1bio-98b4304a/",
            "portfolio": "https://fabiosonats.github.io/my-portifolio/"
        }
    },
    "publishedAt": "2025-01-26T22:00:00Z",
    "updatedAt": "2025-01-26T22:00:00Z",
    "tags": [
        "Python",
        "Data Science",
        "Pandas",
        "NumPy"
    ],
    "category": "python",
    "language": "pt",
    "readingTime": 22,
    "featured": true
}
